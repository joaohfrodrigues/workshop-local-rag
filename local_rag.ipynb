{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local RAG Workshop\n",
    "\n",
    "Welcome to the Local RAG Workshop guide.\n",
    "\n",
    "This interactive notebook will guide you through all the needed steps. You are welcome to extend it after the session and check the shared references to build any application with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import ollama\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from utils import CSVLoader, get_embedding_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load your data\n",
    "\n",
    "In this step, the input context is loaded to a Document list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Name: Introduction to Credit Risk Management\n",
      "Url: https://courses.edx.org/certificates/fb27deecb8f14a7ab635669605a385a5\n",
      "Authority: edX\n",
      "Started On: Dec 2020\n",
      "Finished On: \n",
      "License Number: fb27deecb8f14a7ab635669605a385a5' metadata={'source': 'docs/Certifications.csv', 'row': 1}\n"
     ]
    }
   ],
   "source": [
    "files_list = [f'docs/{f}' for f in listdir(\"docs\") if isfile(join(\"docs\", f))]\n",
    "loader = CSVLoader(file_paths=files_list)\n",
    "docs = loader.load()\n",
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a database to store your document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store each document in a vector embedding database\n",
    "for i, d in enumerate(docs):\n",
    "  response = ollama.embeddings(model=\"mxbai-embed-large\", prompt=d.__str__())\n",
    "  embedding = response[\"embedding\"]\n",
    "  collection.add(\n",
    "    ids=[str(i)],\n",
    "    embeddings=[embedding],\n",
    "    documents=[d.__str__()]\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possible modification\n",
    "\n",
    "Use a cloud-based model with an API key.\n",
    "Check [A Beginner’s Guide to Using OpenAI Text Embedding Models](https://zilliz.com/learn/guide-to-using-openai-text-embedding-models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a base question\n",
    "\n",
    "This will be the question used as basis for your LLM prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"page_content='Name: Merit Diploma x 4 [14/15, 15/16, 16/17, 18/19]\\nUrl: \\nAuthority: Instituto Superior Técnico\\nStarted On: Feb 2020\\nFinished On: \\nLicense Number: ' metadata={'source': 'docs/Certifications.csv', 'row': 0}\", \"page_content='Name: Introduction to Credit Risk Management\\nUrl: https://courses.edx.org/certificates/fb27deecb8f14a7ab635669605a385a5\\nAuthority: edX\\nStarted On: Dec 2020\\nFinished On: \\nLicense Number: fb27deecb8f14a7ab635669605a385a5' metadata={'source': 'docs/Certifications.csv', 'row': 1}\", \"page_content='Name: Microsoft Certified: Azure Data Fundamentals\\nUrl: https://www.credly.com/badges/53b97847-a9bc-465b-8916-66ec26f5c92e?source=linked_in_profile\\nAuthority: Microsoft\\nStarted On: Apr 2021\\nFinished On: \\nLicense Number: ' metadata={'source': 'docs/Certifications.csv', 'row': 3}\", \"page_content='Name: Certified LeSS Practitioner\\nUrl: https://less.works/certificates/joao-fialho-rodrigues-16672249141.pdf\\nAuthority: The LeSS Company\\nStarted On: Nov 2022\\nFinished On: Nov 2024\\nLicense Number: 16672249141' metadata={'source': 'docs/Certifications.csv', 'row': 5}\", \"page_content='Name: Professional Scrum Master™ II (PSM II)\\nUrl: https://www.credly.com/badges/273b2b9d-afe0-4234-ab01-bb923afe18b6/linked_in_profile\\nAuthority: Scrum.org\\nStarted On: Sep 2023\\nFinished On: \\nLicense Number: 1010172' metadata={'source': 'docs/Certifications.csv', 'row': 7}\", \"page_content='Name: Professional Scrum Master™ I (PSM I)\\nUrl: https://www.credly.com/badges/51943a92-71c3-4013-bb33-9af927c92ab1?source=linked_in_profile\\nAuthority: Scrum.org\\nStarted On: Mar 2022\\nFinished On: \\nLicense Number: ' metadata={'source': 'docs/Certifications.csv', 'row': 4}\", \"page_content='Name: Spark and Python for Big Data with PySpark\\nUrl: https://www.udemy.com/certificate/UC-45b45913-b90c-4f7d-a0ed-31a5e39eb740/\\nAuthority: Udemy\\nStarted On: Mar 2021\\nFinished On: \\nLicense Number: UC-45b45913-b90c-4f7d-a0ed-31a5e39eb740' metadata={'source': 'docs/Certifications.csv', 'row': 2}\", \"page_content='Name: Neural Networks and Deep Learning\\nUrl: https://www.coursera.org/account/accomplishments/verify/NQT2H2D3N7RR\\nAuthority: Coursera\\nStarted On: Dec 2022\\nFinished On: \\nLicense Number: NQT2H2D3N7RR' metadata={'source': 'docs/Certifications.csv', 'row': 6}\", \"page_content='Company Name: Critical TechWorks\\nTitle: Data Engineer\\nDescription: - ETL pipelines development in Amazon Web Services (AWS) - AWS experience using resources such as Lambda, S3, Glue, Kinesis among others - Developing transformation code w/ Python - Automating data pipeline deployments in AWS w/ Terraform\\nLocation: Lisbon, Portugal\\nStarted On: May 2021\\nFinished On: Feb 2022' metadata={'source': 'docs/Positions.csv', 'row': 1}\", \"page_content='School Name: Télécom ParisTech\\nStart Date: 2019\\nEnd Date: 2019\\nNotes: 1 week course on quantum entanglement for communications\\nDegree Name: ATHENS Programme\\nActivities: ' metadata={'source': 'docs/Education.csv', 'row': 2}\", \"page_content='Name: Linux' metadata={'source': 'docs/Skills.csv', 'row': 24}\", \"page_content='Name: Cloud Computing' metadata={'source': 'docs/Skills.csv', 'row': 5}\", \"page_content='Company Name: BNP Paribas\\nTitle: Data Analyst / Engineer - Stress Testing Data Analytics\\nDescription: - ETL / ELT processes on credit risk datasets in a big data distributed environment (HDFS) - Operations on large datasets w/ PySpark and HiveSQL - Data visualization and analysis w/ Tableau - Credit risk analysis in the context of EBA S/T and other regulatory frameworks\\nLocation: Lisbon, Portugal\\nStarted On: Nov 2019\\nFinished On: May 2021' metadata={'source': 'docs/Positions.csv', 'row': 2}\", \"page_content='Name: English\\nProficiency: Professional working proficiency' metadata={'source': 'docs/Languages.csv', 'row': 0}\", \"page_content='Name: Arduino' metadata={'source': 'docs/Skills.csv', 'row': 27}\", \"page_content='Name: Agile Methodologies' metadata={'source': 'docs/Skills.csv', 'row': 8}\", \"page_content='Name: Portuguese\\nProficiency: Native or bilingual proficiency' metadata={'source': 'docs/Languages.csv', 'row': 1}\", \"page_content='Name: Spanish\\nProficiency: Elementary proficiency' metadata={'source': 'docs/Languages.csv', 'row': 2}\", \"page_content='Title: Hack For Good - Gulbenkian\\nDescription: - Developing a prototype for an idea related to elderly care and how technology can help us to better prevent and act on emergency situations\\nUrl: \\nStarted On: May 2018\\nFinished On: May 2018' metadata={'source': 'docs/Projects.csv', 'row': 1}\", \"page_content='Company Name: Critical TechWorks\\nTitle: Data Engineer & Scrum Master\\nDescription: \\nLocation: Lisbon, Portugal\\nStarted On: Feb 2022\\nFinished On: ' metadata={'source': 'docs/Positions.csv', 'row': 0}\"]]\n"
     ]
    }
   ],
   "source": [
    "prompt: str = \"What do you know about certifications?\"\n",
    "# Check out the implemenation of get_embedding_data in utils.py\n",
    "data = get_embedding_data(collection, prompt)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q&A with your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No context\n",
    "\n",
    "Try to question the LLM without any context provided by your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "### Template prompting\n",
    "Adding a prompt template maximizes the chance of getting a good answer\n",
    "Below you will find two approaches at this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems like the provided data is related to projects, skills, and languages, but it's not directly related to cooking. However, I can try to provide you with a simple pizza recipe using the format of the provided data.\n",
      "\n",
      "Here's a \"recipe\" in the style of the provided data:\n",
      "\n",
      "```markdown\n",
      "Title: Pizza Recipe\n",
      "Description: - A classic Italian dish made with a combination of ingredients and cooking techniques\n",
      "Url:\n",
      "Started On:\n",
      "Finished On:\n",
      "\n",
      "metadata={'source': 'docs/Recipes.csv', 'row': 1}\n",
      "```\n",
      "\n",
      "And here's the actual recipe in a more readable format:\n",
      "\n",
      "**Pizza Recipe**\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "- Crust: 2 cups of flour, 1 teaspoon of salt, 1 tablespoon of sugar\n",
      "- Sauce: 2 cups of crushed tomatoes, 1/4 cup of olive oil, 4 cloves of garlic, minced\n",
      "- Cheese: 8 ounces of mozzarella, shredded\n",
      "- Toppings: 12 slices of pepperoni, 1 cup of sliced bell peppers, 1 cup of sliced onions\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Preheat the oven to 425°F (220°C).\n",
      "2. Roll out the crust and place it on a baking sheet.\n",
      "3. Spread the sauce over the crust, leaving a small border around the edges.\n",
      "4. Sprinkle the cheese over the sauce.\n",
      "5. Add the toppings of your choice.\n",
      "6. Bake for 15-20 minutes or until the crust is golden brown.\n",
      "\n",
      "Enjoy your delicious homemade pizza!\n",
      "\n",
      "Note: You can add more ingredients and instructions to make this recipe more comprehensive.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Give me a pizza recipe\"\n",
    "\n",
    "# generate a response combining the prompt and data we retrieved in step 2\n",
    "data = get_embedding_data(collection, prompt)\n",
    "output = ollama.generate(\n",
    "  model=\"llama3.2\",\n",
    "  prompt=f\"Using this data: {data}. Respond to this prompt: {prompt}\"\n",
    ")\n",
    "\n",
    "print(output['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing prompt according to needs\n",
    "\n",
    "The prompts used can be optimized according to your use-case needs. For example in the prompt template used below, the answer is shortened to be more concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "# Build prompt\n",
    "full_prompt = f\"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, say that you don't know.\n",
    "Don't give any information besides the provided context.\n",
    "Use five sentences maximum and keep the answer concise.\\n\\n \n",
    "{data}\n",
    "Question: {prompt}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "output = ollama.generate(\n",
    "  model=\"llama3.2\",\n",
    "  prompt=full_prompt\n",
    ")\n",
    "print(output['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End: Tryout the chatbot!\n",
    "\n",
    "You did it! Congrats on completing your first take on building a LLM pipeline with contextual information :D\n",
    "Try the chatbot version by running `streamlit run personal_chatbot_solution.py`.\n",
    "\n",
    "In this chatbot, it is invisible to the user that additional context is being used, makint it seems like a regular chat with the vanilla model. Additionally, memory is added, so it will remember the previous prompts.\n",
    "\n",
    "### Extra challenge!!\n",
    "\n",
    "As an extra exercise, try to get to the solution proposed starting by the default implementation of the chatbot, without context, that you can find in `personal_chatbot_challenge.py`.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
